# CRMArena Data Upload Guide

This guide explains how to upload CRMArena data from the local SQLite database to your Salesforce Developer org.

## Overview

The `upload_data_to_salesforce.py` script:
1. Reads data from `local_data/crmarena_data.db`
2. Handles relationships and ID mapping automatically
3. Uploads records in the correct dependency order
4. Uses Salesforce Bulk API for efficient uploads

## Prerequisites

1. **Schema must be synced first**: Run `sync_schema_to_salesforce.py` to create objects and fields
2. **Salesforce credentials**: Your `.env` file must be configured
3. **Database file**: `local_data/crmarena_data.db` must exist

## Step-by-Step Instructions

### Step 1: Preview the Upload (Dry Run)

Before uploading, preview what will be uploaded:

```bash
cd /Users/tarunanand/Benchmarks/CRMArena
source venv/bin/activate

# Preview with a small sample (5 records per object)
python upload_data_to_salesforce.py --org_type original --dry-run --limit 5
```

This shows:
- How many records will be uploaded per object
- Sample records
- No actual data is uploaded

### Step 2: Test Upload with Small Sample

Test with a small number of records first:

```bash
# Upload 10 records per object
python upload_data_to_salesforce.py --org_type original --limit 10
```

This will:
- Upload a small sample to verify everything works
- Show you any errors before uploading all data
- Create ID mappings for relationships

### Step 3: Upload All Data

Once the test upload works, upload all data:

```bash
# Upload all records (no limit)
python upload_data_to_salesforce.py --org_type original
```

## Command Options

```bash
python upload_data_to_salesforce.py [OPTIONS]
```

**Options:**
- `--org_type {original,b2b,b2c}`: Which org type to upload to (default: `original`)
- `--dry-run`: Preview upload without actually uploading
- `--limit N`: Limit number of records per object (useful for testing)
- `--skip OBJECT1 OBJECT2`: Skip specific objects (e.g., `--skip User Knowledge__kav`)

**Examples:**

```bash
# Dry run with 5 records per object
python upload_data_to_salesforce.py --org_type original --dry-run --limit 5

# Upload 20 records per object
python upload_data_to_salesforce.py --org_type original --limit 20

# Upload all data, skipping User and Knowledge__kav
python upload_data_to_salesforce.py --org_type original --skip User Knowledge__kav

# Upload all data
python upload_data_to_salesforce.py --org_type original
```

## Upload Order

Records are uploaded in dependency order:

1. **User** - Skipped (requires special setup)
2. **Account** - No dependencies
3. **ProductCategory** - No dependencies
4. **Product2** - No dependencies
5. **Pricebook2** - No dependencies
6. **Contact** - Depends on: Account, User
7. **Issue__c** - No dependencies
8. **Case** - Depends on: Account, Contact, User, Issue__c, OrderItem
9. **Order** - Depends on: Account, Pricebook2
10. **OrderItem** - Depends on: Order, Product2, PricebookEntry
11. **PricebookEntry** - Depends on: Pricebook2, Product2
12. **ProductCategoryProduct** - Depends on: ProductCategory, Product2
13. **EmailMessage** - Depends on: Case
14. **LiveChatTranscript** - Depends on: Account, Case, Contact, User
15. **CaseHistory__c** - Depends on: Case, User
16. **Knowledge__kav** - No dependencies (requires Knowledge to be enabled)

## How ID Mapping Works

The script automatically handles ID mapping:

1. **Old IDs** from the database are stored
2. **New IDs** are generated by Salesforce when records are created
3. **Lookup fields** are automatically updated with new IDs
4. **Relationships** are preserved across all objects

For example:
- If Account `001ABC` becomes `001XYZ` in your org
- All Contact records referencing `001ABC` will automatically use `001XYZ`

## Special Objects

### User Object

The User object is **skipped by default** because:
- Users require special permissions to create via API
- Users typically need to be created in Setup → Users
- Or require "Manage Users" permission

**To create users manually:**
1. Go to Setup → Users → Users
2. Create users matching the data in the database
3. Or use the `--skip User` flag to skip it

### Knowledge__kav

Requires Knowledge to be enabled (see `ENABLE_KNOWLEDGE_GUIDE.md`).

If Knowledge is not enabled, use:
```bash
python upload_data_to_salesforce.py --org_type original --skip Knowledge__kav
```

## Troubleshooting

### Error: "INVALID_FIELD"

**Cause**: Field doesn't exist in your org
**Solution**: Run `sync_schema_to_salesforce.py` first to create all fields

### Error: "INVALID_ID" or "referenceTo value does not resolve"

**Cause**: Referenced record doesn't exist (dependency issue)
**Solution**: 
- Make sure objects are uploaded in order
- Check that parent records were created successfully
- Re-run the script (it will skip existing records)

### Error: "DUPLICATE_VALUE"

**Cause**: Record with same unique field already exists
**Solution**: The script will skip duplicates automatically

### Error: "INSUFFICIENT_ACCESS"

**Cause**: Your user doesn't have permission to create records
**Solution**: 
- Check your user profile permissions
- Ensure "Create" permission on objects
- For Developer orgs, you should have full access

### ID Mapping Not Working

**Cause**: Records failed to upload, so IDs weren't mapped
**Solution**:
- Check error messages for failed records
- Fix the issues (usually missing fields or invalid data)
- Re-run the script (it will map IDs correctly)

## Data Verification

After uploading, verify the data:

```python
from crm_sandbox.env.connect_sandbox import SalesforceConnector

sf = SalesforceConnector(org_type="original")

# Check Account count
result, status = sf.run_query("SELECT COUNT() FROM Account")
print(f"Accounts: {result}")

# Check Case count
result, status = sf.run_query("SELECT COUNT() FROM Case")
print(f"Cases: {result}")

# Check a specific record
result, status = sf.run_query("SELECT Id, Name FROM Account LIMIT 5")
print(f"Sample Accounts: {result}")
```

## Performance Notes

- **Bulk API**: Uses Salesforce Bulk API for efficient uploads
- **Batch Size**: Processes records in batches of 10,000
- **Rate Limits**: Respects Salesforce API rate limits
- **Large Datasets**: For very large datasets, consider using `--limit` to upload in chunks

## Next Steps

After uploading data:

1. **Verify Records**: Check that records were created in Salesforce
2. **Test Queries**: Run some CRMArena tasks to verify data is accessible
3. **Check Relationships**: Verify that lookup relationships are working
4. **Run Tasks**: Execute CRMArena evaluation tasks

## Summary

The data upload process:
1. ✅ Reads from SQLite database
2. ✅ Handles ID mapping automatically
3. ✅ Uploads in correct dependency order
4. ✅ Preserves all relationships
5. ✅ Uses efficient Bulk API
6. ✅ Provides detailed progress and error reporting

Your CRMArena data is now ready to use in your Salesforce Developer org!

